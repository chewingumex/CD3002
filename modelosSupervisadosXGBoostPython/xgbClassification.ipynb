{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42189bf6-0bc8-4caa-ad59-c89d0574e627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4a92c3-640c-42cf-a131-454d77713ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create xgboost matrices\n",
    "\n",
    "def makeXGBMatrix(data, label):\n",
    "\n",
    "    return xgboost.DMatrix(data,\n",
    "                           label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890024d7-9c04-45ab-8710-012822419c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findXGBClassification(trainXGB,\n",
    "                          testXGB,\n",
    "                          xtrain,\n",
    "                          ytrain,\n",
    "                          xtest,\n",
    "                          ytest,\n",
    "                          iters):\n",
    "    \n",
    "    # iniciar el valor de la metrica del cual partimos (alto para metricas que queremos reducir\n",
    "    # y viceversa\n",
    "    \n",
    "    best_metric = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    # muestrear numeros de forma aleatoria (dentro de un rango) para los hyperparámetros \n",
    "    # cada iteracion \n",
    "    \n",
    "    for iteration in range(iters):\n",
    "\n",
    "        params = {\n",
    "                'tree_method' : 'exact',\n",
    "                'booster' : 'gbtree', # 'gblinear'\n",
    "                'eta' : random.uniform(0.01, 0.3),\n",
    "                'max_depth' : random.randint(5,14),\n",
    "                'reg_lambda' : random.uniform(0.01, 0.4),\n",
    "                'reg_alpha' : random.uniform(0.01, 0.4),\n",
    "                'gamma' : random.randint(0, 20),\n",
    "                'subsample' : random.uniform(0.5, 1),\n",
    "                'colsample_bytree' : random.uniform(0.5, 1),\n",
    "                'objective' : 'binary:logistic',\n",
    "                'eval_metric' : 'auc'\n",
    "            }\n",
    "    \n",
    "    # ajustar un modelo utilizando validacion cruzada para probar los hiperparámetros en\n",
    "    # todas las regiones de los datos de entrenamiento\n",
    "    \n",
    "        xgb_cv = xgboost.cv(\n",
    "            params = params, \n",
    "            dtrain = trainXGB, \n",
    "               nfold=10,\n",
    "               metrics={'auc'}, \n",
    "               seed=2345,\n",
    "               callbacks=[xgboost.callback.EvaluationMonitor(show_stdv=True),\n",
    "                          xgboost.callback.EarlyStopping(2)]\n",
    "        )\n",
    " \n",
    "    # registrar la metrica\n",
    "    \n",
    "        auc = xgb_cv.iloc[-1,2]\n",
    "    \n",
    "    # si la metrica alcanzada fuera mejor que la actual, reemplazar la actual  y guardar los\n",
    "    # hiperparámetros del modelo que llegó a ella.\n",
    "    # Nota : la metrica debe ser menor si se esta reduciendo (ej rmse) o mayor si se esta aumentando (ej auc)\n",
    "    \n",
    "        if auc > best_metric:\n",
    "\n",
    "            best_metric = auc\n",
    "            best_params = params\n",
    "    \n",
    "    # Ajustar un modelo final con los mejores hiperparámetros, probándolo ahora en el test set\n",
    "    \n",
    "    final_model = xgboost.XGBClassifier( \n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=2,\n",
    "        n_estimators=1000000\n",
    "    )\n",
    "\n",
    "    final_model.set_params(**best_params)\n",
    "\n",
    "    final_model.fit(\n",
    "        X=xtrain,\n",
    "        y=ytrain,\n",
    "        eval_set = [(xtrain, ytrain),(xtest, ytest)]\n",
    "    )\n",
    "    \n",
    "    return final_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
